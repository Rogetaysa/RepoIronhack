{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice de contenidos\n",
    "1. Antes de empezar\n",
    "\n",
    "2. Reto 1 - Explorar el conjunto de datos\n",
    "\n",
    "    2.0.0.1 Explore los datos a vista de pájaro.\n",
    "    \n",
    "    2.0.0.2 A continuación, evalúe si las columnas de este conjunto de datos están fuertemente correlacionadas.\n",
    "\n",
    "3. Reto 2 - Eliminar la colinealidad de columnas.\n",
    "\n",
    "4. Reto 3 - Manejar los valores perdidos\n",
    "\n",
    "    4.0.0.1 En las celdas siguientes, trate los valores que faltan en el conjunto de datos. Recuerde comentar los fundamentos de sus decisiones.\n",
    "    \n",
    "    4.0.0.2 De nuevo, examine el número de valores que faltan en cada columna.\n",
    "\n",
    "5. Reto 4 - Manejo de datos categóricos WHOIS_*\n",
    "    \n",
    "    5.0.0.1 En las celdas siguientes, fije los valores de los países como se ha indicado anteriormente.\n",
    "    \n",
    "    5.0.0.2 Si un número limitado de valores representa la mayoría de los datos, podemos conservar estos valores principales y volver a etiquetar todos los demás valores poco frecuentes.\n",
    "    \n",
    "    5.0.0.3 Después de comprobarlo, mantengamos los 10 valores principales de la columna y reetiquetemos las demás columnas con OTROS.\n",
    "    \n",
    "    5.0.0.4 En la siguiente celda, elimine ['WHOIS_STATEPRO', 'WHOIS_REGDATE', 'WHOIS_UPDATED_DATE'].\n",
    "\n",
    "6. Reto 5 - Manejar los datos categóricos restantes y convertirlos en ordinales\n",
    "    \n",
    "    6.0.0.1 URL es fácil. Simplemente la eliminaremos porque tiene demasiados valores únicos que no hay forma de consolidar.\n",
    "    \n",
    "    6.0.0.2 Imprima el conteo de valores únicos de CHARSET. Puede ver que sólo hay unos pocos valores únicos. Así que podemos dejarlo como está.\n",
    "    \n",
    "    6.0.0.3 Antes de pensar en su propia solución, no lea las instrucciones que vienen a continuación.\n",
    "\n",
    "7. Desafío 6 - Modelado, predicción y evaluación\n",
    "    \n",
    "    7.0.0.1 En este laboratorio probaremos dos modelos diferentes y compararemos nuestros resultados.\n",
    "    \n",
    "    7.0.0.2 Nuestro segundo algoritmo es DecisionTreeClassifier.\n",
    "    \n",
    "    7.0.0.3 Crearemos otro modelo DecisionTreeClassifier con max_depth=5.\n",
    "\n",
    "8. Bonus Challenge - Escalado de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antes de empezar:\n",
    "- Lee el archivo README.md\n",
    "- Comenta todo lo que puedas y utiliza los recursos del archivo README.md\n",
    "- ¡Feliz aprendizaje!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries:\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este laboratorio, exploraremos un conjunto de datos que describe sitios web con diferentes características y los etiqueta como benignos o maliciosos. Utilizaremos algoritmos de aprendizaje supervisado para averiguar qué patrones de características es probable que tengan los sitios web maliciosos y utilizaremos nuestro modelo para predecir sitios web maliciosos.\n",
    "\n",
    "Sus características serán:\n",
    "\n",
    "+ URL: es la identificación anónima de la URL analizada en el estudio\n",
    "+ URL_LENGTH: es el número de caracteres de la URL\n",
    "+ NUMBER_SPECIAL_CHARACTERS: es el número de caracteres especiales identificados en la URL, como, «/», «%», «#», «&», «. “, ”=»\n",
    "+ CHARSET: es un valor categórico y su significado es el estándar de codificación de caracteres (también llamado juego de caracteres).\n",
    "+ SERVER: es un valor categórico y su significado es el sistema operativo del servidor obtenido de la respuesta del paquete.\n",
    "+ CONTENT_LENGTH: representa el tamaño del contenido de la cabecera HTTP.\n",
    "+ WHOIS_COUNTRY: es una variable categórica, sus valores son los países que obtuvimos de la respuesta del servidor (en concreto, nuestro script utilizó la API de Whois).\n",
    "+ WHOIS_STATEPRO: es una variable categórica, sus valores son los estados que obtuvimos de la respuesta del servidor (en concreto, nuestro script utilizó la API de Whois).\n",
    "+ WHOIS_REGDATE: Whois proporciona la fecha de registro del servidor, por tanto, esta variable tiene valores de fecha con formato DD/MM/AAAA HH:MM\n",
    "+ WHOIS_UPDATED_DATE: A través del Whois obtenemos la última fecha de actualización del servidor analizado\n",
    "+ TCP_CONVERSATION_EXCHANGE: Esta variable es el número de paquetes TCP intercambiados entre el servidor y nuestro cliente honeypot\n",
    "+ DIST_REMOTE_TCP_PORT: es el número de puertos detectados y diferentes a TCP\n",
    "+ REMOTE_IPS: esta variable tiene el número total de IPs conectadas al honeypot\n",
    "+ APP_BYTES: es el número de bytes transferidos\n",
    "+ SOURCE_APP_PACKETS: paquetes enviados desde el honeypot al servidor\n",
    "+ REMOTE_APP_PACKETS: paquetes recibidos del servidor\n",
    "+ APP_PACKETS: número total de paquetes IP generados durante la comunicación entre el honeypot y el servidor.\n",
    "+ DNS_QUERY_TIMES: número de paquetes DNS generados durante la comunicación entre el honeypot y el servidor.\n",
    "+ TYPE: es una variable categórica, sus valores representan el tipo de página web analizada, en concreto, 1 es para sitios web maliciosos y 0 para sitios web benignos\n",
    "\n",
    "# Desafío 1 - Explorar el conjunto de datos\n",
    "\n",
    "Empecemos explorando el conjunto de datos. Primero carga el archivo de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = pd.read_csv('/Users/gabrielrogetdeaysa/Library/CloudStorage/GoogleDrive-rogetaysa@gmail.com/La meva unitat/IronhackGD/Repoironhack/Entregas/44-lab-supervised-learning-es-main/website.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore los datos a vista de pájaro.\n",
    "\n",
    "Ahora ya deberías estar muy familiarizado con los procedimientos, así que no te daremos las instrucciones paso a paso. Reflexiona sobre lo que hiciste en los laboratorios anteriores y explora el conjunto de datos.\n",
    "\n",
    "Cosas que buscarás:\n",
    "\n",
    "* ¿Qué aspecto tiene el conjunto de datos?\n",
    "* ¿Cuáles son los tipos de datos?\n",
    "* ¿Qué columnas contienen las características de los sitios web?\n",
    "* ¿Qué columna contiene la característica que vamos a predecir? ¿Cuál es el código de los sitios web benignos frente a los maliciosos?\n",
    "* ¿Necesitamos transformar alguna de las columnas de categórica a ordinal? En caso afirmativo, ¿cuáles son esas columnas?\n",
    "\n",
    "Siéntete libre de añadir celdas adicionales para tus exploraciones. Asegúrate de comentar lo que descubras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>CHARSET</th>\n",
       "      <th>SERVER</th>\n",
       "      <th>CONTENT_LENGTH</th>\n",
       "      <th>WHOIS_COUNTRY</th>\n",
       "      <th>WHOIS_STATEPRO</th>\n",
       "      <th>WHOIS_REGDATE</th>\n",
       "      <th>WHOIS_UPDATED_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>REMOTE_APP_BYTES</th>\n",
       "      <th>APP_PACKETS</th>\n",
       "      <th>DNS_QUERY_TIMES</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0_109</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>iso-8859-1</td>\n",
       "      <td>nginx</td>\n",
       "      <td>263.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/10/2015 18:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1153</td>\n",
       "      <td>832</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0_2314</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>Apache/2.4.10</td>\n",
       "      <td>15087.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1230</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>1265</td>\n",
       "      <td>1230</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0_911</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>us-ascii</td>\n",
       "      <td>Microsoft-HTTPAPI/2.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0_113</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "      <td>nginx</td>\n",
       "      <td>162.0</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>7/10/1997 4:00</td>\n",
       "      <td>12/09/2013 0:45</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3812</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>18784</td>\n",
       "      <td>4380</td>\n",
       "      <td>39</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0_403</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124140.0</td>\n",
       "      <td>US</td>\n",
       "      <td>TX</td>\n",
       "      <td>12/05/1996 0:00</td>\n",
       "      <td>11/04/2017 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4278</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>129889</td>\n",
       "      <td>4586</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       URL  URL_LENGTH  NUMBER_SPECIAL_CHARACTERS     CHARSET  \\\n",
       "0   M0_109          16                          7  iso-8859-1   \n",
       "1  B0_2314          16                          6       UTF-8   \n",
       "2   B0_911          16                          6    us-ascii   \n",
       "3   B0_113          17                          6  ISO-8859-1   \n",
       "4   B0_403          17                          6       UTF-8   \n",
       "\n",
       "                  SERVER  CONTENT_LENGTH WHOIS_COUNTRY WHOIS_STATEPRO  \\\n",
       "0                  nginx           263.0           NaN            NaN   \n",
       "1          Apache/2.4.10         15087.0           NaN            NaN   \n",
       "2  Microsoft-HTTPAPI/2.0           324.0           NaN            NaN   \n",
       "3                  nginx           162.0            US             AK   \n",
       "4                    NaN        124140.0            US             TX   \n",
       "\n",
       "      WHOIS_REGDATE WHOIS_UPDATED_DATE  ...  DIST_REMOTE_TCP_PORT  REMOTE_IPS  \\\n",
       "0  10/10/2015 18:21                NaN  ...                     0           2   \n",
       "1               NaN                NaN  ...                     7           4   \n",
       "2               NaN                NaN  ...                     0           0   \n",
       "3    7/10/1997 4:00    12/09/2013 0:45  ...                    22           3   \n",
       "4   12/05/1996 0:00    11/04/2017 0:00  ...                     2           5   \n",
       "\n",
       "   APP_BYTES  SOURCE_APP_PACKETS  REMOTE_APP_PACKETS  SOURCE_APP_BYTES  \\\n",
       "0        700                   9                  10              1153   \n",
       "1       1230                  17                  19              1265   \n",
       "2          0                   0                   0                 0   \n",
       "3       3812                  39                  37             18784   \n",
       "4       4278                  61                  62            129889   \n",
       "\n",
       "   REMOTE_APP_BYTES  APP_PACKETS  DNS_QUERY_TIMES  Type  \n",
       "0               832            9              2.0     1  \n",
       "1              1230           17              0.0     0  \n",
       "2                 0            0              0.0     0  \n",
       "3              4380           39              8.0     0  \n",
       "4              4586           61              4.0     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What the dataset looks like?\n",
    "websites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1781 entries, 0 to 1780\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   URL                        1781 non-null   object \n",
      " 1   URL_LENGTH                 1781 non-null   int64  \n",
      " 2   NUMBER_SPECIAL_CHARACTERS  1781 non-null   int64  \n",
      " 3   CHARSET                    1774 non-null   object \n",
      " 4   SERVER                     1605 non-null   object \n",
      " 5   CONTENT_LENGTH             969 non-null    float64\n",
      " 6   WHOIS_COUNTRY              1475 non-null   object \n",
      " 7   WHOIS_STATEPRO             1419 non-null   object \n",
      " 8   WHOIS_REGDATE              1654 non-null   object \n",
      " 9   WHOIS_UPDATED_DATE         1642 non-null   object \n",
      " 10  TCP_CONVERSATION_EXCHANGE  1781 non-null   int64  \n",
      " 11  DIST_REMOTE_TCP_PORT       1781 non-null   int64  \n",
      " 12  REMOTE_IPS                 1781 non-null   int64  \n",
      " 13  APP_BYTES                  1781 non-null   int64  \n",
      " 14  SOURCE_APP_PACKETS         1781 non-null   int64  \n",
      " 15  REMOTE_APP_PACKETS         1781 non-null   int64  \n",
      " 16  SOURCE_APP_BYTES           1781 non-null   int64  \n",
      " 17  REMOTE_APP_BYTES           1781 non-null   int64  \n",
      " 18  APP_PACKETS                1781 non-null   int64  \n",
      " 19  DNS_QUERY_TIMES            1780 non-null   float64\n",
      " 20  Type                       1781 non-null   int64  \n",
      "dtypes: float64(2), int64(12), object(7)\n",
      "memory usage: 292.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# What are the data types?\n",
    "websites.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1781 entries, 0 to 1780\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   URL                        1781 non-null   object \n",
      " 1   URL_LENGTH                 1781 non-null   int64  \n",
      " 2   NUMBER_SPECIAL_CHARACTERS  1781 non-null   int64  \n",
      " 3   CHARSET                    1774 non-null   object \n",
      " 4   SERVER                     1605 non-null   object \n",
      " 5   CONTENT_LENGTH             969 non-null    float64\n",
      " 6   WHOIS_COUNTRY              1475 non-null   object \n",
      " 7   WHOIS_STATEPRO             1419 non-null   object \n",
      " 8   WHOIS_REGDATE              1654 non-null   object \n",
      " 9   WHOIS_UPDATED_DATE         1642 non-null   object \n",
      " 10  TCP_CONVERSATION_EXCHANGE  1781 non-null   int64  \n",
      " 11  DIST_REMOTE_TCP_PORT       1781 non-null   int64  \n",
      " 12  REMOTE_IPS                 1781 non-null   int64  \n",
      " 13  APP_BYTES                  1781 non-null   int64  \n",
      " 14  SOURCE_APP_PACKETS         1781 non-null   int64  \n",
      " 15  REMOTE_APP_PACKETS         1781 non-null   int64  \n",
      " 16  SOURCE_APP_BYTES           1781 non-null   int64  \n",
      " 17  REMOTE_APP_BYTES           1781 non-null   int64  \n",
      " 18  APP_PACKETS                1781 non-null   int64  \n",
      " 19  DNS_QUERY_TIMES            1780 non-null   float64\n",
      " 20  Type                       1781 non-null   int64  \n",
      "dtypes: float64(2), int64(12), object(7)\n",
      "memory usage: 292.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Which columns contain the features of the websites?\n",
    "websites.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which column contains the feature we will predict? What is the code standing for benign vs malicious websites?\n",
    "#Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 for bening 1 for maliciuos websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we need to transform any of the columns from categorical to ordinal values? If so what are these columns?\n",
    "# Yes, \n",
    "def analyze_columns(websites):\n",
    "    for column in websites.columns:\n",
    "        print(f\"Tabla de frecuencias para la columna '{column}':\")\n",
    "        print(websites[column].value_counts())\n",
    "        num_unique = websites[column].nunique()\n",
    "        print(f'\\nNúmero de valores únicos en {column}: {num_unique}')\n",
    "        print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de frecuencias para la columna 'URL':\n",
      "URL\n",
      "M0_109     1\n",
      "B0_999     1\n",
      "B0_2292    1\n",
      "B0_2168    1\n",
      "B0_2108    1\n",
      "          ..\n",
      "B0_104     1\n",
      "M1_3       1\n",
      "M0_53      1\n",
      "M0_50      1\n",
      "B0_676     1\n",
      "Name: count, Length: 1781, dtype: int64\n",
      "\n",
      "Número de valores únicos en URL: 1781\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'URL_LENGTH':\n",
      "URL_LENGTH\n",
      "39     86\n",
      "40     48\n",
      "46     44\n",
      "42     43\n",
      "38     43\n",
      "       ..\n",
      "134     1\n",
      "131     1\n",
      "107     1\n",
      "128     1\n",
      "249     1\n",
      "Name: count, Length: 142, dtype: int64\n",
      "\n",
      "Número de valores únicos en URL_LENGTH: 142\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'NUMBER_SPECIAL_CHARACTERS':\n",
      "NUMBER_SPECIAL_CHARACTERS\n",
      "9     274\n",
      "8     211\n",
      "11    208\n",
      "10    198\n",
      "7     159\n",
      "6     148\n",
      "12    134\n",
      "13     92\n",
      "14     58\n",
      "15     50\n",
      "17     42\n",
      "20     41\n",
      "16     35\n",
      "19     27\n",
      "18     26\n",
      "21     14\n",
      "22     10\n",
      "23     10\n",
      "24      7\n",
      "25      7\n",
      "26      7\n",
      "27      6\n",
      "29      4\n",
      "34      3\n",
      "5       2\n",
      "28      2\n",
      "31      2\n",
      "36      1\n",
      "30      1\n",
      "43      1\n",
      "40      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Número de valores únicos en NUMBER_SPECIAL_CHARACTERS: 31\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'CHARSET':\n",
      "CHARSET\n",
      "UTF-8           676\n",
      "ISO-8859-1      427\n",
      "utf-8           379\n",
      "us-ascii        155\n",
      "iso-8859-1      134\n",
      "windows-1251      1\n",
      "ISO-8859          1\n",
      "windows-1252      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Número de valores únicos en CHARSET: 8\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'SERVER':\n",
      "SERVER\n",
      "Apache                                                       386\n",
      "nginx                                                        211\n",
      "Microsoft-HTTPAPI/2.0                                        113\n",
      "cloudflare-nginx                                              94\n",
      "Microsoft-IIS/7.5                                             51\n",
      "                                                            ... \n",
      "mw2103.codfw.wmnet                                             1\n",
      "Apache/2.4.25 (Debian)                                         1\n",
      "ECD (fll/0790)                                                 1\n",
      "Apache/2.4.25 (FreeBSD) OpenSSL/1.0.1s-freebsd PHP/5.6.30      1\n",
      "Apache/2.2.16 (Debian)                                         1\n",
      "Name: count, Length: 238, dtype: int64\n",
      "\n",
      "Número de valores únicos en SERVER: 238\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'CONTENT_LENGTH':\n",
      "CONTENT_LENGTH\n",
      "324.0      138\n",
      "1819.0      20\n",
      "2516.0      13\n",
      "162.0       12\n",
      "345.0       11\n",
      "          ... \n",
      "226.0        1\n",
      "217.0        1\n",
      "4695.0       1\n",
      "636.0        1\n",
      "24435.0      1\n",
      "Name: count, Length: 637, dtype: int64\n",
      "\n",
      "Número de valores únicos en CONTENT_LENGTH: 637\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'WHOIS_COUNTRY':\n",
      "WHOIS_COUNTRY\n",
      "US                1103\n",
      "CA                  84\n",
      "ES                  63\n",
      "AU                  35\n",
      "PA                  21\n",
      "GB                  19\n",
      "JP                  11\n",
      "UK                  10\n",
      "CN                  10\n",
      "IN                  10\n",
      "FR                   9\n",
      "CZ                   9\n",
      "NL                   6\n",
      "CH                   6\n",
      "[u'GB'; u'UK']       5\n",
      "KR                   5\n",
      "PH                   4\n",
      "BS                   4\n",
      "ru                   4\n",
      "AT                   4\n",
      "HK                   3\n",
      "us                   3\n",
      "TR                   3\n",
      "BE                   3\n",
      "DE                   3\n",
      "SC                   3\n",
      "KY                   3\n",
      "SE                   3\n",
      "BR                   2\n",
      "UY                   2\n",
      "Cyprus               2\n",
      "SI                   2\n",
      "UA                   2\n",
      "RU                   2\n",
      "IL                   2\n",
      "NO                   2\n",
      "KG                   2\n",
      "TH                   1\n",
      "se                   1\n",
      "LV                   1\n",
      "LU                   1\n",
      "United Kingdom       1\n",
      "UG                   1\n",
      "PK                   1\n",
      "IT                   1\n",
      "BY                   1\n",
      "AE                   1\n",
      "IE                   1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Número de valores únicos en WHOIS_COUNTRY: 48\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'WHOIS_STATEPRO':\n",
      "WHOIS_STATEPRO\n",
      "CA           372\n",
      "NY            75\n",
      "WA            65\n",
      "Barcelona     62\n",
      "FL            61\n",
      "            ... \n",
      "Alicante       1\n",
      "SK             1\n",
      "TR             1\n",
      "RIX            1\n",
      "Paris          1\n",
      "Name: count, Length: 181, dtype: int64\n",
      "\n",
      "Número de valores únicos en WHOIS_STATEPRO: 181\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'WHOIS_REGDATE':\n",
      "WHOIS_REGDATE\n",
      "17/09/2008 0:00    62\n",
      "13/01/2001 0:12    59\n",
      "31/07/2000 0:00    47\n",
      "15/02/2005 0:00    41\n",
      "29/03/1997 0:00    33\n",
      "                   ..\n",
      "23/11/1994 0:00     1\n",
      "30/08/2015 0:00     1\n",
      "30/04/2009 0:00     1\n",
      "27/11/2006 0:00     1\n",
      "14/11/2008 0:00     1\n",
      "Name: count, Length: 890, dtype: int64\n",
      "\n",
      "Número de valores únicos en WHOIS_REGDATE: 890\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'WHOIS_UPDATED_DATE':\n",
      "WHOIS_UPDATED_DATE\n",
      "2/09/2016 0:00      64\n",
      "12/12/2015 10:16    59\n",
      "29/06/2016 0:00     47\n",
      "14/01/2017 0:00     42\n",
      "29/11/2016 0:00     36\n",
      "                    ..\n",
      "5/05/2013 3:46       1\n",
      "21/07/2016 18:54     1\n",
      "5/09/2016 3:47       1\n",
      "19/04/2017 17:24     1\n",
      "9/12/2016 0:00       1\n",
      "Name: count, Length: 593, dtype: int64\n",
      "\n",
      "Número de valores únicos en WHOIS_UPDATED_DATE: 593\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'TCP_CONVERSATION_EXCHANGE':\n",
      "TCP_CONVERSATION_EXCHANGE\n",
      "0      657\n",
      "7       56\n",
      "8       53\n",
      "5       48\n",
      "4       48\n",
      "      ... \n",
      "85       1\n",
      "103      1\n",
      "90       1\n",
      "709      1\n",
      "95       1\n",
      "Name: count, Length: 103, dtype: int64\n",
      "\n",
      "Número de valores únicos en TCP_CONVERSATION_EXCHANGE: 103\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'DIST_REMOTE_TCP_PORT':\n",
      "DIST_REMOTE_TCP_PORT\n",
      "0      916\n",
      "3      151\n",
      "1      106\n",
      "2       78\n",
      "4       69\n",
      "      ... \n",
      "59       1\n",
      "279      1\n",
      "33       1\n",
      "67       1\n",
      "89       1\n",
      "Name: count, Length: 66, dtype: int64\n",
      "\n",
      "Número de valores únicos en DIST_REMOTE_TCP_PORT: 66\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'REMOTE_IPS':\n",
      "REMOTE_IPS\n",
      "0     657\n",
      "2     191\n",
      "3     183\n",
      "5     134\n",
      "4     128\n",
      "1     101\n",
      "6      97\n",
      "7      80\n",
      "8      67\n",
      "9      42\n",
      "10     30\n",
      "11     25\n",
      "12     21\n",
      "14      9\n",
      "13      8\n",
      "15      5\n",
      "16      2\n",
      "17      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Número de valores únicos en REMOTE_IPS: 18\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'APP_BYTES':\n",
      "APP_BYTES\n",
      "0       657\n",
      "432      20\n",
      "366      20\n",
      "498      18\n",
      "564      12\n",
      "       ... \n",
      "2657      1\n",
      "3079      1\n",
      "54        1\n",
      "1198      1\n",
      "6631      1\n",
      "Name: count, Length: 825, dtype: int64\n",
      "\n",
      "Número de valores únicos en APP_BYTES: 825\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'SOURCE_APP_PACKETS':\n",
      "SOURCE_APP_PACKETS\n",
      "0      655\n",
      "5       43\n",
      "4       42\n",
      "8       38\n",
      "6       38\n",
      "      ... \n",
      "159      1\n",
      "187      1\n",
      "76       1\n",
      "131      1\n",
      "99       1\n",
      "Name: count, Length: 113, dtype: int64\n",
      "\n",
      "Número de valores únicos en SOURCE_APP_PACKETS: 113\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'REMOTE_APP_PACKETS':\n",
      "REMOTE_APP_PACKETS\n",
      "0      590\n",
      "5       48\n",
      "4       48\n",
      "2       43\n",
      "9       42\n",
      "      ... \n",
      "263      1\n",
      "144      1\n",
      "145      1\n",
      "255      1\n",
      "157      1\n",
      "Name: count, Length: 116, dtype: int64\n",
      "\n",
      "Número de valores únicos en REMOTE_APP_PACKETS: 116\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'SOURCE_APP_BYTES':\n",
      "SOURCE_APP_BYTES\n",
      "0        590\n",
      "124       43\n",
      "244       31\n",
      "186       29\n",
      "306       24\n",
      "        ... \n",
      "12884      1\n",
      "12416      1\n",
      "12354      1\n",
      "5911       1\n",
      "3039       1\n",
      "Name: count, Length: 885, dtype: int64\n",
      "\n",
      "Número de valores únicos en SOURCE_APP_BYTES: 885\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'REMOTE_APP_BYTES':\n",
      "REMOTE_APP_BYTES\n",
      "0       655\n",
      "366      20\n",
      "432      20\n",
      "498      18\n",
      "474      12\n",
      "       ... \n",
      "6657      1\n",
      "3248      1\n",
      "2497      1\n",
      "3531      1\n",
      "2776      1\n",
      "Name: count, Length: 822, dtype: int64\n",
      "\n",
      "Número de valores únicos en REMOTE_APP_BYTES: 822\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'APP_PACKETS':\n",
      "APP_PACKETS\n",
      "0      655\n",
      "5       43\n",
      "4       42\n",
      "8       38\n",
      "6       38\n",
      "      ... \n",
      "159      1\n",
      "187      1\n",
      "76       1\n",
      "131      1\n",
      "99       1\n",
      "Name: count, Length: 113, dtype: int64\n",
      "\n",
      "Número de valores únicos en APP_PACKETS: 113\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'DNS_QUERY_TIMES':\n",
      "DNS_QUERY_TIMES\n",
      "0.0     976\n",
      "4.0     309\n",
      "6.0     213\n",
      "2.0     142\n",
      "8.0     105\n",
      "10.0     19\n",
      "12.0     12\n",
      "14.0      2\n",
      "20.0      1\n",
      "9.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Número de valores únicos en DNS_QUERY_TIMES: 10\n",
      "-------------------------------------------------------------\n",
      "Tabla de frecuencias para la columna 'Type':\n",
      "Type\n",
      "0    1565\n",
      "1     216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Número de valores únicos en Type: 2\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "analyze_columns(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/2_6279bj5gg1whljcz1prc680000gn/T/ipykernel_28589/77040158.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  websites[\"CHARSET\"].replace(\"utf-8\", \"UTF-8\", inplace=True)\n",
      "/var/folders/qp/2_6279bj5gg1whljcz1prc680000gn/T/ipykernel_28589/77040158.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  websites[\"CHARSET\"].replace(\"iso-8859-1\", \"ISO-8859-1\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "websites[\"CHARSET\"].replace(\"utf-8\", \"UTF-8\", inplace=True)\n",
    "websites[\"CHARSET\"].replace(\"iso-8859-1\", \"ISO-8859-1\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A continuación, evalúe si las columnas de este conjunto de datos están fuertemente correlacionadas.\n",
    "\n",
    "En el laboratorio de aprendizaje supervisado Mushroom que hicimos recientemente, mencionamos que nos preocupa si nuestro conjunto de datos tiene columnas fuertemente correlacionadas porque si es el caso tenemos que elegir ciertos algoritmos de ML en lugar de otros. Ahora tenemos que evaluar esto para nuestro conjunto de datos.\n",
    "\n",
    "Por suerte, la mayoría de las columnas de este conjunto de datos son ordinales, lo que nos facilita mucho las cosas. En las siguientes celdas, evalúe el nivel de colinealidad de los datos.\n",
    "\n",
    "Aquí tienes algunas indicaciones generales que puede consultar para completar este paso:\n",
    "\n",
    "1. Crea una matriz de correlaciones utilizando las columnas numéricas del conjunto de datos.\n",
    "\n",
    "2. Crea un mapa de calor utilizando `seaborn` para visualizar qué columnas tienen una alta colinealidad.\n",
    "\n",
    "3. Comenta qué columnas podría necesitar eliminar debido a la alta colinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'M0_109'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your code here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m websites\u001b[38;5;241m.\u001b[39mcorr()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, na_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1753\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'M0_109'"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "correlation_matrix = websites.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este es un ejemplo para conocer la importancia de las características usando un modelo ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = websites._get_numeric_data().drop('Type', axis=1)\n",
    "y = websites.Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = xgb.feature_importances_.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.barh(X.columns[sort_idx],xgb.feature_importances_[sort_idx])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    En el gráfico anterior podemos ver las características con menor peso en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío 2 - Eliminar la colinealidad de columnas.\n",
    "\n",
    "En el mapa de calor que ha creado, deberías haber visto al menos 3 columnas que pueden eliminarse debido a la alta colinealidad. Elimina estas columnas del conjunto de datos.\n",
    "\n",
    "Ten en cuenta que debes eliminar el menor número posible de columnas. No tienes que eliminar todas las columnas a la vez. En su lugar, intenta eliminar una columna y, a continuación, vuelve a elaborar el mapa térmico para determinar si deben eliminarse columnas adicionales. Cuando el conjunto de datos ya no contenga columnas correlacionadas en más de un 90%, puedes parar. Además, ten en cuenta que cuando dos columnas tienen una alta colinealidad, sólo necesitas eliminar una de ellas, pero no ambas.\n",
    "\n",
    "En las celdas de abajo, elimina tantas columnas como puedas para eliminar la alta colinealidad en el conjunto de datos. Asegúrate de comentar tu camino para que se pueda conocer tu razonamiento, lo que permitirá dar feedback. Al final, vuelve a imprimir el mapa de calor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE THE 4 COLUMNS WITH MORE COLLINEARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 3 - Manejar los valores que faltan\n",
    "\n",
    "El siguiente paso sería manejar los valores faltantes. **Comenzamos examinando el número de valores que faltan en cada columna.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firts we will drop the columns with more than 50% of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will drop the rows with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De nuevo, examina el número de valores que faltan en cada columna. \n",
    "\n",
    "    Si todos están limpios, procede. Si no, vuelve atrás y haz más limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine missing values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 4 - Manejar datos categóricos `WHOIS_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias columnas categóricas que necesitamos manejar. Estas columnas son:\n",
    "\n",
    "* URL\n",
    "* CHARSET\n",
    "* SERVIDOR\n",
    "* PAÍS\n",
    "* «WHOIS_STATEPRO\n",
    "* WHOIS_REGDATE\n",
    "* WHOIS_UPDATED_DATE\n",
    "\n",
    "La forma de tratar las columnas de cadena es siempre caso por caso. Empecemos trabajando con `WHOIS_COUNTRY`. Tus pasos son:\n",
    "\n",
    "1. Enumera los valores únicos de `WHOIS_COUNTRY`.\n",
    "1. Consolide los valores de país con códigos de país coherentes. Por ejemplo, los siguientes valores se refieren al mismo país y deben utilizar un código de país coherente:\n",
    "    * `CY` y `Cyprus`.\n",
    "    * US y US\n",
    "    * SE y SE\n",
    "    * GB, Reino Unido y GB, Reino Unido.\n",
    "\n",
    "#### En las celdas de abajo, fija los valores de los países como se indica arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "websites.WHOIS_COUNTRY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "good_country = {'None':'None', \n",
    "                'US':'US', \n",
    "                'SC':'SC', \n",
    "                'GB':'UK', \n",
    "                'UK':'UK', \n",
    "                'RU':'RU', \n",
    "                'AU':'AU', \n",
    "                'CA':'CA',\n",
    "                'PA':'PA',\n",
    "                'se':'SE', \n",
    "                'IN':'IN',\n",
    "                'LU':'LU', \n",
    "                'TH':'TH', \n",
    "                \"[u'GB'; u'UK']\":'UK', \n",
    "                'FR':'FR',\n",
    "                'NL':'NL',\n",
    "                'UG':'UG', \n",
    "                'JP':'JP', \n",
    "                'CN':'CN', \n",
    "                'SE':'SE',\n",
    "                'SI':'SI', \n",
    "                'IL':'IL', \n",
    "                'ru':'RU', \n",
    "                'KY':'KY', \n",
    "                'AT':'AT', \n",
    "                'CZ':'CZ', \n",
    "                'PH':'PH', \n",
    "                'BE':'BE', \n",
    "                'NO':'NO', \n",
    "                'TR':'TR', \n",
    "                'LV':'LV',\n",
    "                'DE':'DE', \n",
    "                'ES':'ES', \n",
    "                'BR':'BR', \n",
    "                'us':'US', \n",
    "                'KR':'KR', \n",
    "                'HK':'HK', \n",
    "                'UA':'UA', \n",
    "                'CH':'CH', \n",
    "                'United Kingdom':'UK',\n",
    "                'BS':'BS', \n",
    "                'PK':'PK', \n",
    "                'IT':'IT', \n",
    "                'Cyprus':'CY', \n",
    "                'BY':'BY', \n",
    "                'AE':'AE', \n",
    "                'IE':'IE', \n",
    "                'UY':'UY', \n",
    "                'KG':'KG'}\n",
    "\n",
    "websites.WHOIS_COUNTRY = websites.WHOIS_COUNTRY.apply(lambda x : good_country[x])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites.WHOIS_COUNTRY.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que hemos fijado los valores de los países, ¿podemos convertir ahora esta columna en ordinal?\n",
    "\n",
    "Todavía no. Si reflexionas, en los laboratorios anteriores sobre cómo manejamos las columnas categóricas, probablemente recuerdes que acabamos eliminando muchas de esas columnas porque hay demasiados valores únicos. Demasiados valores únicos en una columna no es deseable en el aprendizaje automático porque hace que la predicción sea inexacta. Pero hay soluciones bajo ciertas condiciones. Una de las condiciones solucionables es:\n",
    "\n",
    "#### Si un número limitado de valores representa la mayoría de los datos, podemos conservar estos valores principales y volver a etiquetar todos los demás valores poco frecuentes.\n",
    "\n",
    "La columna `WHOIS_COUNTRY` resulta ser este caso. Puedes comprobarlo imprimiendo un gráfico de barras de los `value_counts` en la siguiente celda para verificarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def print_bar_plot(x,y):\n",
    "    plt.bar(x, y)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_bar_plot(websites.WHOIS_COUNTRY.unique(),websites.WHOIS_COUNTRY.value_counts());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Después de verificar, ahora vamos a mantener los 10 primeros valores de la columna y volver a etiquetar otras columnas con `OTHER`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que se ha cambiado la etiqueta `WHOIS_COUNTRY`, ya no necesitamos `WHOIS_STATEPRO` porque los valores de los estados o provincias pueden dejar de ser relevantes. Eliminaremos esta columna.\n",
    "\n",
    "Además, también eliminaremos `WHOIS_REGDATE` y `WHOIS_UPDATED_DATE`. Se trata de las fechas de registro y actualización de los dominios del sitio web. No son de nuestra incumbencia.\n",
    "\n",
    "#### En la siguiente celda, elimina `['WHOIS_STATEPRO', 'WHOIS_REGDATE', 'WHOIS_UPDATED_DATE']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 5 - Manejar los datos categóricos restantes y convertirlos en ordinales\n",
    "\n",
    "Ahora vuelve a imprimir los `dtypes` de los datos. Además de `WHOIS_COUNTRY` que ya hemos arreglado, deberían quedar 3 columnas categóricas: `URL`, `CHARSET`, y `SERVER`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `URL` es fácil. Simplemente lo eliminaremos porque tiene demasiados valores únicos que no hay forma de consolidar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprime el recuento de valores únicos de `CHARSET`. Usted ve que hay sólo unos pocos valores únicos. Así que podemos dejarlo como está."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SERVER` es un poco más complicado. Imprime sus valores únicos y piensa cómo puedes consolidar esos valores.\n",
    "\n",
    "#### Antes de pensar en tu propia solución, no leas las instrucciones que vienen a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque hay tantos valores únicos en la columna `SERVER`, en realidad sólo hay 3 tipos principales de servidores: Microsoft, Apache y Nginx. Simplemente comprueba si cada valor de `SERVER` contiene alguno de esos tipos de servidor y vuelve a etiquetarlos. Para los valores `SERVER` que no contengan ninguna de esas subcadenas, etiquétalos con `Other`.\n",
    "\n",
    "Al final, la columna «SERVIDOR» sólo debe contener 4 valores únicos: `Microsoft`, `Apache`, `nginx`, y `Other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count `SERVER` value counts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, todos nuestros datos categóricos están fijados ahora. **Vamos a convertirlos en datos ordinales usando la función `get_dummies` de Pandas ([documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)). Asegúrate de eliminar las columnas categóricas pasando `drop_first=True` a `get_dummies` ya que no las necesitamos. **Además, asigna los datos con valores ficticios a una nueva variable `website_dummy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, inspeccione `website_dummy` para asegurarse de que los datos y tipos son los previstos - no debería haber ninguna columna categórica en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío 6 - Modelado, predicción y evaluación\n",
    "\n",
    "Comenzaremos esta sección dividiendo los datos en train y test. **Nombra tus 4 variables `X_entrenamiento`, `X_prueba`, `y_entrenamiento` y `y_prueba`. Selecciona el 80% de los datos para entrenar y el 20% para probar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este laboratorio, probaremos dos modelos diferentes y compararemos nuestros resultados.\n",
    "\n",
    "El primer modelo que utilizaremos en este laboratorio es la regresión logística. Ya hemos aprendido sobre la regresión logística como algoritmo de clasificación. En la celda de abajo, cargue `LogisticRegression` de scikit-learn e inicialice el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, ajustamos el modelo a nuestros datos de entrenamiento. Ya hemos separado nuestros datos en 4 partes. Utilízalos en tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, importamos `confusion_matrix` y `accuracy_score` de `sklearn.metrics` y ajustamos nuestros datos de prueba. Asigna los datos ajustados a `y_pred` e imprime la matriz de confusión y la puntuación de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué opinas del rendimiento del modelo? Escribe tus conclusiones a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nuestro segundo algoritmo es DecisionTreeClassifier\n",
    "\n",
    "Aunque no es necesario, vamos a ajustar un modelo utilizando los datos de entrenamiento y luego probar el rendimiento del modelo utilizando los datos de prueba. Empezaremos cargando `DecisionTreeClassifier` de scikit-learn y luego inicializando y ajustando el modelo. Empezaremos con un modelo donde max_depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar tu modelo, calcula las probabilidades predichas, decide 0 o 1 utilizando un umbral de 0,5 e imprime la matriz de confusión, así como la puntuación de precisión (en el conjunto de prueba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos a crear otro modelo DecisionTreeClassifier con max_depth=5. \n",
    "Inicia y ajusta el modelo de abajo e imprime la matriz de confusión y la puntuación de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Has observado una mejora en la matriz de confusión al aumentar max_depth a 5? ¿Has observado una mejora en la puntuación de precisión? Escribe tus conclusiones a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Add your conclusion here -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Escalado de características\n",
    "\n",
    "La resolución de problemas en el aprendizaje automático es iterativa. Puede mejorar la predicción de su modelo con diversas técnicas (aunque hay un punto óptimo para el tiempo que invierte y la mejora que obtiene). Ahora sólo has completado una iteración del análisis ML. Hay más iteraciones que puedes realizar para introducir mejoras. Para poder hacerlo, necesitarás conocimientos más profundos en estadística y dominar más técnicas de análisis de datos. En este bootcamp, no tenemos tiempo para alcanzar ese objetivo avanzado. Pero harás esfuerzos constantes después del bootcamp para conseguirlo finalmente.\n",
    "\n",
    "Sin embargo, ahora sí queremos que aprendas una de las técnicas avanzadas que se llama *feature scaling*. La idea del escalado de características es estandarizar/normalizar el rango de variables independientes o características de los datos. Esto puede hacer que los valores atípicos sean más evidentes para que pueda eliminarlos. Este paso debe realizarse durante el Desafío 6 después de dividir los datos de entrenamiento y de prueba, ya que no desea dividir los datos de nuevo, lo que hace imposible comparar los resultados con y sin el escalado de características. Para conceptos generales sobre el escalado de características, haga clic [aquí](https://en.wikipedia.org/wiki/Feature_scaling). Para profundizar, haga clic [aquí](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e).\n",
    "\n",
    "En la siguiente celda, intente mejorar la precisión de predicción de su modelo mediante el escalado de características. Una librería que puedes utilizar es `sklearn.preprocessing.RobustScaler` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)). Utilizarás `RobustScaler` para ajustar y transformar tu `X_train`, y luego transformar `X_test`. Utilizarás la regresión logística para ajustar y predecir tus datos transformados y obtener la puntuación de precisión de la misma manera. Compare la puntuación de precisión con sus datos normalizados con los datos de precisión anteriores. ¿Se ha producido alguna mejora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your comments here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
